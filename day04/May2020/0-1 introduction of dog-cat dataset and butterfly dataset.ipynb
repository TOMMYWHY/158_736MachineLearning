{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs&cats datasets\n",
    "Dataset: Dogs&Cats include 12.5K color cat images and 12.5K color dog images(150 by 150 pixels). \n",
    "es\n",
    "<img src=\"d&c.jpg\" style=\"zoom:50%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) generate training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../train/asset3.zip', '../train/asset2.zip', '../train/omniglot.zip', '../train/asset4.zip', '../train/test_data.pkl', '../train/train1.zip', '../train/figures', '../train/data.pkl', '../train/house_data.pkl']\n",
      "error:../train/asset3.zip\n",
      "error:../train/asset2.zip\n",
      "error:../train/omniglot.zip\n",
      "error:../train/asset4.zip\n",
      "error:../train/test_data.pkl\n",
      "error:../train/train1.zip\n",
      "error:../train/figures\n",
      "error:../train/data.pkl\n",
      "error:../train/house_data.pkl\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "# Read all files from the fold \n",
    "_dataset_path = '../train/'\n",
    "files = glob.glob(_dataset_path+\"*\")  #glob.glob is to extract the file into list\n",
    "print(files)\n",
    "# save all cat images in cat_files\n",
    "# print(files)\n",
    "cat_files = []\n",
    "dog_files = []\n",
    "\n",
    "for f in files:\n",
    "    fn = f.split('\\\\')[-1].split('.')[0]\n",
    "#     fn = f.split('/')[-1].split('.')[0]\n",
    "#     print(fn)\n",
    "    if fn == 'cat':\n",
    "        cat_files.append(f)\n",
    "    elif fn == 'dog':\n",
    "        dog_files.append(f)\n",
    "    else:\n",
    "        print(\"error:{}\".format(f))\n",
    "print(len(cat_files))\n",
    "print(len(dog_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(0,)\n",
      "Cat datasets: (0,) (0,) (0,)\n",
      "Dog datasets: (0,) (0,) (0,)\n"
     ]
    }
   ],
   "source": [
    "cat_files = np.array(cat_files)\n",
    "dog_files = np.array(dog_files)\n",
    "print(cat_files.shape)\n",
    "np.random.shuffle(cat_files)\n",
    "np.random.shuffle(dog_files)\n",
    "print(cat_files.shape)\n",
    "cat_train = cat_files[:1500]\n",
    "cat_val = cat_files[1500:2000]\n",
    "cat_test = cat_files[2000:2500]\n",
    "\n",
    "dog_train = dog_files[:1500]\n",
    "dog_val = dog_files[1500:2000]\n",
    "dog_test = dog_files[2000:2500]\n",
    "print('Cat datasets:', cat_train.shape, cat_val.shape, cat_test.shape)\n",
    "print('Dog datasets:', dog_train.shape, dog_val.shape, dog_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Save 3 data sets in individual fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a) generate folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "def create_folder(_fold_path):\n",
    "    try:\n",
    "        os.makedirs(_fold_path)\n",
    "    except OSError:\n",
    "        print(\"***folder already exist***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***folder already exist***\n",
      "***folder already exist***\n",
      "***folder already exist***\n"
     ]
    }
   ],
   "source": [
    "_asset_path = 'asset4/dog_cat/'\n",
    "\n",
    "#named the directory of data set\n",
    "train_dir = _asset_path+'training_data/'\n",
    "val_dir = _asset_path+'validation_data/'\n",
    "test_dir = _asset_path+'test_data/'\n",
    "\n",
    "create_folder(train_dir)\n",
    "create_folder(val_dir)\n",
    "create_folder(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = np.append(cat_train, dog_train)\n",
    "validate_files = np.append(cat_val, dog_val)\n",
    "test_files = np.append(cat_test, dog_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copy2\n",
    "def copy_to_dir(src_path, dst_path):\n",
    "    for f in src_path:\n",
    "        f_name = f.split(\"\\\\\")[-1]\n",
    "        copy2(f,dst_path+f_name)\n",
    "    print(\"sucess\")     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sucess\n",
      "sucess\n",
      "sucess\n"
     ]
    }
   ],
   "source": [
    "copy_to_dir(train_files, train_dir)\n",
    "copy_to_dir(validate_files, val_dir)\n",
    "copy_to_dir(test_files, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b) save data sets in build folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 3)\n",
      "Train dataset shape: (3000, 150, 150, 3) \tValidation dataset shape: (1000, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "IMG_DIM = (150, 150)\n",
    "\n",
    "# To extract the samples from directory of train\n",
    "train_files = glob.glob(train_dir+\"*\") \n",
    "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
    "train_imgs = np.array(train_imgs)\n",
    "print(train_imgs[1].shape)\n",
    "train_labels = [fn.split('\\\\')[-1].split('.')[0].strip() for fn in train_files]\n",
    "\n",
    "# To extract the samples from directory of val\n",
    "validation_files = glob.glob(val_dir+'*')\n",
    "validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]\n",
    "validation_imgs = np.array(validation_imgs)\n",
    "validation_labels = [fn.split('\\\\')[-1].split('.')[0].strip() for fn in validation_files]\n",
    "\n",
    "test_files = glob.glob(test_dir+'*')\n",
    "test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in test_files]\n",
    "\n",
    "test_imgs = np.array(test_imgs)\n",
    "test_labels = [fn.split('\\\\')[-1].split('.')[0].strip() for fn in test_files]\n",
    "# print(test_imgs[1])\n",
    "print('Train dataset shape:', train_imgs.shape, \n",
    "      '\\tValidation dataset shape:', validation_imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c) transfer category labels to discrete values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: ['asset4/dog_cat/validation_data/cat', 'asset4/dog_cat/validation_data/dog']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-a2c5f5b2d78d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_labels_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mvalidation_labels_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest_labels_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         return _encode_numpy(values, uniques, encode,\n\u001b[0;32m--> 118\u001b[0;31m                              check_unknown=check_unknown)\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[0;32m---> 50\u001b[0;31m                                  % str(diff))\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: ['asset4/dog_cat/validation_data/cat', 'asset4/dog_cat/validation_data/dog']"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# encode labels\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_enc = le.transform(train_labels)\n",
    "validation_labels_enc = le.transform(validation_labels)\n",
    "test_labels_enc = le.transform(test_labels)\n",
    "print(test_labels_enc.shape)\n",
    "print(train_labels[0:5], train_labels_enc[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Butterfly daatset\n",
    "Dataset: Butterfly daatset include 319 color Butterfly(150 by 150 pixels). \n",
    "es\n",
    "<img src=\"butt.jpg\" style=\"zoom:50%\" />\n",
    "The training, validation, and test sets have been save in the folds, './asset3/data/train/','./asset3/data/valid/','./asset3/data/test/'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMG_3380_2.jpg', 'IMG_3415_2.jpg', 'IMG_3411_6.jpg', 'IMG_3386_4.jpg', 'IMG_3413_4.jpg', 'IMG_3413_5.jpg', 'IMG_3384_7.jpg', 'IMG_3382_1.jpg', 'IMG_3415_3.jpg', 'IMG_3380_3.jpg', 'IMG_3380_1.jpg', 'IMG_3415_1.jpg', 'IMG_3404_9.jpg', 'IMG_3413_6.jpg', 'IMG_3411_4.jpg', 'IMG_3384_4.jpg', 'IMG_3417_2.jpg', 'IMG_3391_8.jpg', 'IMG_3408_1.jpg', 'IMG_3415_4.jpg', 'IMG_3395_8.jpg', 'IMG_3413_2.jpg', 'IMG_3413_3.jpg', 'IMG_3411_1.jpg', 'IMG_3382_7.jpg', 'IMG_3415_5.jpg', 'IMG_3382_5.jpg', 'IMG_3402_9.jpg', 'IMG_3386_1.jpg', 'IMG_3411_2.jpg', 'IMG_3402_8.jpg', 'IMG_3382_4.jpg', 'IMG_3415_6.jpg', 'IMG_3385_5.jpg', 'IMG_3410_5.jpg', 'IMG_3409_4.jpg', 'IMG_3409_5.jpg', 'IMG_3416_2.jpg', 'IMG_3410_4.jpg', 'IMG_3385_4.jpg', 'IMG_3412_6.jpg', 'IMG_3412_4.jpg', 'IMG_3410_6.jpg', 'IMG_3381_2.jpg', 'IMG_3409_7.jpg', 'IMG_3392_8.jpg', 'IMG_3414_3.jpg', 'IMG_3409_6.jpg', 'IMG_3416_1.jpg', 'IMG_3410_7.jpg', 'IMG_3412_5.jpg', 'IMG_3385_3.jpg', 'IMG_3410_3.jpg', 'IMG_3416_5.jpg', 'IMG_3381_7.jpg', 'IMG_3414_6.jpg', 'IMG_3409_3.jpg', 'IMG_3416_4.jpg', 'IMG_3403_8.jpg', 'IMG_3385_2.jpg', 'IMG_3394_8.jpg', 'IMG_3412_2.jpg', 'IMG_3416_6.jpg', 'IMG_3414_4.jpg', 'IMG_3381_5.jpg', 'IMG_3412_3.jpg', 'IMG_3394_9.jpg', 'IMG_3387_3.jpg', 'IMG_3374_1.jpg', 'IMG_3389_1.jpg', 'IMG_3396_6.jpg', 'IMG_3403_6.jpg', 'IMG_3392_2.jpg', 'IMG_3407_2.jpg', 'IMG_3407_3.jpg', 'IMG_3392_3.jpg', 'IMG_3390_1.jpg', 'IMG_3403_7.jpg', 'IMG_3396_7.jpg', 'IMG_3394_5.jpg', 'IMG_3374_2.jpg', 'IMG_3394_7.jpg', 'IMG_3396_5.jpg', 'IMG_3403_5.jpg', 'IMG_3405_3.jpg', 'IMG_3392_1.jpg', 'IMG_3407_1.jpg', 'IMG_3403_4.jpg', 'IMG_3389_3.jpg', 'IMG_3401_6.jpg', 'IMG_3374_3.jpg', 'IMG_3394_2.jpg', 'IMG_3407_4.jpg', 'IMG_3407_5.jpg', 'IMG_3396_1.jpg', 'IMG_3401_3.jpg', 'IMG_3389_6.jpg', 'IMG_3374_6.jpg', 'IMG_3394_3.jpg', 'IMG_3394_1.jpg', 'IMG_3374_4.jpg', 'IMG_3403_3.jpg', 'IMG_3409_8.jpg', 'IMG_3392_7.jpg', 'IMG_3407_7.jpg', 'IMG_3407_6.jpg', 'IMG_3392_6.jpg', 'IMG_3390_4.jpg', 'IMG_3403_2.jpg', 'IMG_3389_5.jpg', 'IMG_3374_5.jpg', 'IMG_3406_1.jpg', 'IMG_3391_3.jpg', 'IMG_3402_5.jpg', 'IMG_3375_2.jpg', 'IMG_3395_7.jpg', 'IMG_3388_2.jpg', 'IMG_3388_3.jpg', 'IMG_3395_6.jpg', 'IMG_3402_4.jpg', 'IMG_3377_1.jpg', 'IMG_3391_2.jpg', 'IMG_3406_2.jpg', 'IMG_3402_6.jpg', 'IMG_3388_1.jpg', 'IMG_3395_5.jpg', 'IMG_3402_7.jpg', 'IMG_3377_2.jpg', 'IMG_3419_4.jpg', 'IMG_3391_1.jpg', 'IMG_3393_3.jpg', 'IMG_3393_7.jpg', 'IMG_3406_7.jpg', 'IMG_3391_5.jpg', 'IMG_3402_3.jpg', 'IMG_3395_1.jpg', 'IMG_3375_4.jpg', 'IMG_3402_2.jpg', 'IMG_3391_4.jpg', 'IMG_3406_6.jpg', 'IMG_3393_6.jpg', 'IMG_3393_4.jpg', 'IMG_3406_4.jpg', 'IMG_3391_6.jpg', 'IMG_3395_2.jpg', 'IMG_3395_3.jpg', 'IMG_3402_1.jpg', 'IMG_3377_4.jpg', 'IMG_3391_7.jpg', 'IMG_3406_5.jpg', 'IMG_3393_5.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "# imagelist = os.listdir('./asset3/data/train/male')\n",
    "imagelist = os.listdir('../train/asset3/data/train/male')\n",
    "print(imagelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "#Extract images from fplders\n",
    "# _asset_path = './asset3/data/train/'\n",
    "_asset_path = '../train/asset3/data/train/'\n",
    "train_dir = _asset_path+'male/'\n",
    "train_files = glob.glob(train_dir+\"*\")\n",
    "print(len(train_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "IMG_DIM = (150, 150)\n",
    "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
    "train_imgs = np.array(train_imgs)\n",
    "print(train_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
