{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tommy/opt/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/Tommy/opt/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/Tommy/opt/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/Tommy/opt/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/Tommy/opt/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/Tommy/opt/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "IMG_DIM = (150, 150)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "(3000, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "_data_path = '../datasets and figures/asset2/dog_cat/'\n",
    "\n",
    "\n",
    "# _data_path = './asset2/dog_cat/'\n",
    "\n",
    "train_dir = _data_path+\"training_data/\"\n",
    "valid_dir = _data_path+\"validation_data/\"\n",
    "test_dir = _data_path+\"test_data/\"\n",
    "\n",
    "train_files = glob.glob(train_dir+\"*\") \n",
    "print(len(train_files))\n",
    "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
    "train_imgs = np.array(train_imgs)\n",
    "train_labels = [fn.split('\\\\')[-1].split('.')[0].strip() for fn in train_files]\n",
    "print(train_imgs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_enc = le.transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,Input\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cov2D takes the input_shape  as (150,150,3)\n",
    "\n",
    "### Cov1D takes the input_shape as (1,150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Tommy/opt/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 75, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 38, 38, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 19, 19, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               6554112   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 6,851,073\n",
      "Trainable params: 6,851,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build model\n",
    "input_shape=(150,150,3)\n",
    "img_input = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(img_input)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x= Flatten()(x)\n",
    "x = Dense(512,activation='relu')(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "output = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = Model(img_input, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Tommy/opt/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/3\n",
      "2400/2400 [==============================] - 81s 34ms/step - loss: 0.1544 - accuracy: 0.9658 - val_loss: 1.0000e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "2400/2400 [==============================] - 74s 31ms/step - loss: 1.0000e-07 - accuracy: 1.0000 - val_loss: 1.0000e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "2400/2400 [==============================] - 72s 30ms/step - loss: 1.0000e-07 - accuracy: 1.0000 - val_loss: 1.0000e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x631ac0160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "# model.fit(train_imgs,train_labels_enc, steps_per_epoch=100, epochs=20,\n",
    "#                               validation_data=val_generator, validation_steps=50, verbose=1)\n",
    "model.fit(train_imgs, train_labels_enc, batch_size=225 ,epochs=3, validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Extract output of 'layer[10](dense_7)'\n",
    "intermediate_layer_model = Model(inputs = model.input, outputs = model.layers[10].output)\n",
    "intermediate_layer_output = intermediate_layer_model.predict(train_imgs)\n",
    "print(type(intermediate_layer_output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_1/Relu:0\", shape=(?, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[10].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Classification using kNN\n",
    "\n",
    "train_x = intermediate_layer_output[0:2000]\n",
    "train_label = train_labels_enc[0:2000]\n",
    "test_x = intermediate_layer_output[2000:3000]\n",
    "test_label = train_labels_enc[2000:3000]\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_3 = KNeighborsClassifier(n_neighbors=3) # Testing with k = 3\n",
    "knn_3.fit(train_x,train_label)\n",
    "y_pred_knn = knn_3.predict(test_x)\n",
    "score = knn_3.score(test_x,test_label)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from datetime import datetime\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Activation, Flatten, Dense, UpSampling2D\n",
    "from keras.models import *\n",
    "from keras.optimizers import SGD,Adam,Adagrad,Nadam,RMSprop\n",
    "from keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "from keras.models import Model\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "_data_path = '../datasets and figures/asset2/dog_cat/'\n",
    "\n",
    "# _asset_path = 'asset2/dog_cat/'\n",
    "\n",
    "train_dir = _asset_path+'training_data/'\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "IMG_DIM = (48, 48)\n",
    "\n",
    "\n",
    "train_files = glob.glob(train_dir+\"*\") \n",
    "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
    "train_imgs = np.array(train_imgs)\n",
    "print(train_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 64)        9280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 48, 48, 3)         1731      \n",
      "=================================================================\n",
      "Total params: 24,739\n",
      "Trainable params: 24,547\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(48, 48, 3)      \n",
    "img_input = Input(shape=input_shape)       \n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(img_input)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "model = Model(img_input, decoded)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 21s 9ms/step - loss: -78.0071 - val_loss: -4328.5440\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 21s 9ms/step - loss: -436.2186 - val_loss: -9663.1027\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 21s 9ms/step - loss: -888.5355 - val_loss: -7873.5651\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 21s 9ms/step - loss: -1444.0336 - val_loss: -8248.3335\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 21s 9ms/step - loss: -2088.4288 - val_loss: -17288.4038\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "hist = model.fit(train_imgs, train_imgs,\n",
    "                epochs=5,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 24, 24, 16)\n"
     ]
    }
   ],
   "source": [
    "#Extract output of 'layer[3](max_pooling2d_24)'\n",
    "intermediate_layer_model = Model(inputs = model.input, outputs = model.layers[3].output)\n",
    "intermediate_layer_output = intermediate_layer_model.predict(train_imgs)\n",
    "print(intermediate_layer_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 9216)\n"
     ]
    }
   ],
   "source": [
    "train_imgs = intermediate_layer_output.reshape((len(intermediate_layer_output), np.prod(intermediate_layer_output.shape[1:])))\n",
    "print(train_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9216)\n",
      "(1000,)\n",
      "0.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xzhu2\\Documents\\ProgramData\\anaconda3\\envs\\AML158736\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_imgs[0:2000]\n",
    "train_label = train_labels_enc[0:2000]\n",
    "test_x = train_imgs[2000:3000]\n",
    "test_label = train_labels_enc[2000:3000]\n",
    "print(test_x.shape)\n",
    "print(test_label.shape)\n",
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "\n",
    "lr.fit(train_x,train_label)  ## decoded_imgs_train: (60000, 64) \n",
    "\n",
    "y_pred_lr = lr.predict(test_x)  ## encoded_imgs_test: (10000, 64)\n",
    "score1 = lr.score(test_x,test_label)\n",
    "# score2 = lr.score(decoded_imgs_train,train_labels)\n",
    "print(score1)\n",
    "# print(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
