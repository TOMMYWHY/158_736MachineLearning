{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load your own path here where the datasets reside\n",
    "# path = '/home/brett/Documents/Datasets/ten-datasets/'\n",
    "path = '../ten-datasets/'\n",
    "\n",
    "#load the dataset into a dataframe\n",
    "polishdata = loadmat(path + 'Polish.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only looking at a single year at this stage. Not sure whether they is need to join up multiple years or not.\n",
    "df = pd.DataFrame(polishdata['year5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088238</td>\n",
       "      <td>0.55472</td>\n",
       "      <td>0.01134</td>\n",
       "      <td>1.0205</td>\n",
       "      <td>-66.5200</td>\n",
       "      <td>0.342040</td>\n",
       "      <td>0.109490</td>\n",
       "      <td>0.57752</td>\n",
       "      <td>1.0881</td>\n",
       "      <td>0.32036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080955</td>\n",
       "      <td>0.275430</td>\n",
       "      <td>0.91905</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>7.2711</td>\n",
       "      <td>4.7343</td>\n",
       "      <td>142.760</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>3.2597</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006202</td>\n",
       "      <td>0.48465</td>\n",
       "      <td>0.23298</td>\n",
       "      <td>1.5998</td>\n",
       "      <td>6.1825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>1.06340</td>\n",
       "      <td>1.2757</td>\n",
       "      <td>0.51535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028591</td>\n",
       "      <td>-0.012035</td>\n",
       "      <td>1.00470</td>\n",
       "      <td>0.152220</td>\n",
       "      <td>6.0911</td>\n",
       "      <td>3.2749</td>\n",
       "      <td>111.140</td>\n",
       "      <td>3.2841</td>\n",
       "      <td>3.3700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130240</td>\n",
       "      <td>0.22142</td>\n",
       "      <td>0.57751</td>\n",
       "      <td>3.6082</td>\n",
       "      <td>120.0400</td>\n",
       "      <td>0.187640</td>\n",
       "      <td>0.162120</td>\n",
       "      <td>3.05900</td>\n",
       "      <td>1.1415</td>\n",
       "      <td>0.67731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123960</td>\n",
       "      <td>0.192290</td>\n",
       "      <td>0.87604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.7934</td>\n",
       "      <td>2.9870</td>\n",
       "      <td>71.531</td>\n",
       "      <td>5.1027</td>\n",
       "      <td>5.6188</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089951</td>\n",
       "      <td>0.88700</td>\n",
       "      <td>0.26927</td>\n",
       "      <td>1.5222</td>\n",
       "      <td>-55.9920</td>\n",
       "      <td>-0.073957</td>\n",
       "      <td>-0.089951</td>\n",
       "      <td>0.12740</td>\n",
       "      <td>1.2754</td>\n",
       "      <td>0.11300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418840</td>\n",
       "      <td>-0.796020</td>\n",
       "      <td>0.59074</td>\n",
       "      <td>2.878700</td>\n",
       "      <td>7.6524</td>\n",
       "      <td>3.3302</td>\n",
       "      <td>147.560</td>\n",
       "      <td>2.4735</td>\n",
       "      <td>5.9299</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048179</td>\n",
       "      <td>0.55041</td>\n",
       "      <td>0.10765</td>\n",
       "      <td>1.2437</td>\n",
       "      <td>-22.9590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>0.81682</td>\n",
       "      <td>1.5150</td>\n",
       "      <td>0.44959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.107160</td>\n",
       "      <td>0.77048</td>\n",
       "      <td>0.139380</td>\n",
       "      <td>10.1180</td>\n",
       "      <td>4.0950</td>\n",
       "      <td>106.430</td>\n",
       "      <td>3.4294</td>\n",
       "      <td>3.3622</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2       3         4         5         6        7   \\\n",
       "0  0.088238  0.55472  0.01134  1.0205  -66.5200  0.342040  0.109490  0.57752   \n",
       "1 -0.006202  0.48465  0.23298  1.5998    6.1825  0.000000 -0.006202  1.06340   \n",
       "2  0.130240  0.22142  0.57751  3.6082  120.0400  0.187640  0.162120  3.05900   \n",
       "3 -0.089951  0.88700  0.26927  1.5222  -55.9920 -0.073957 -0.089951  0.12740   \n",
       "4  0.048179  0.55041  0.10765  1.2437  -22.9590  0.000000  0.059280  0.81682   \n",
       "\n",
       "       8        9   ...        55        56       57        58       59  \\\n",
       "0  1.0881  0.32036  ...  0.080955  0.275430  0.91905  0.002024   7.2711   \n",
       "1  1.2757  0.51535  ... -0.028591 -0.012035  1.00470  0.152220   6.0911   \n",
       "2  1.1415  0.67731  ...  0.123960  0.192290  0.87604  0.000000   8.7934   \n",
       "3  1.2754  0.11300  ...  0.418840 -0.796020  0.59074  2.878700   7.6524   \n",
       "4  1.5150  0.44959  ...  0.240400  0.107160  0.77048  0.139380  10.1180   \n",
       "\n",
       "       60       61      62      63   64  \n",
       "0  4.7343  142.760  2.5568  3.2597  0.0  \n",
       "1  3.2749  111.140  3.2841  3.3700  0.0  \n",
       "2  2.9870   71.531  5.1027  5.6188  0.0  \n",
       "3  3.3302  147.560  2.4735  5.9299  0.0  \n",
       "4  4.0950  106.430  3.4294  3.3622  0.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the following creates an 80/20 train/test split but this could be done more easily using sklearn functions which I'll look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a random number column so that we can split the data\n",
    "df['random_sample'] = np.random.rand(1,len(df)).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>random_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088238</td>\n",
       "      <td>0.55472</td>\n",
       "      <td>0.01134</td>\n",
       "      <td>1.0205</td>\n",
       "      <td>-66.5200</td>\n",
       "      <td>0.342040</td>\n",
       "      <td>0.109490</td>\n",
       "      <td>0.57752</td>\n",
       "      <td>1.0881</td>\n",
       "      <td>0.32036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275430</td>\n",
       "      <td>0.91905</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>7.2711</td>\n",
       "      <td>4.7343</td>\n",
       "      <td>142.760</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>3.2597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006202</td>\n",
       "      <td>0.48465</td>\n",
       "      <td>0.23298</td>\n",
       "      <td>1.5998</td>\n",
       "      <td>6.1825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>1.06340</td>\n",
       "      <td>1.2757</td>\n",
       "      <td>0.51535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012035</td>\n",
       "      <td>1.00470</td>\n",
       "      <td>0.152220</td>\n",
       "      <td>6.0911</td>\n",
       "      <td>3.2749</td>\n",
       "      <td>111.140</td>\n",
       "      <td>3.2841</td>\n",
       "      <td>3.3700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130240</td>\n",
       "      <td>0.22142</td>\n",
       "      <td>0.57751</td>\n",
       "      <td>3.6082</td>\n",
       "      <td>120.0400</td>\n",
       "      <td>0.187640</td>\n",
       "      <td>0.162120</td>\n",
       "      <td>3.05900</td>\n",
       "      <td>1.1415</td>\n",
       "      <td>0.67731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192290</td>\n",
       "      <td>0.87604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.7934</td>\n",
       "      <td>2.9870</td>\n",
       "      <td>71.531</td>\n",
       "      <td>5.1027</td>\n",
       "      <td>5.6188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089951</td>\n",
       "      <td>0.88700</td>\n",
       "      <td>0.26927</td>\n",
       "      <td>1.5222</td>\n",
       "      <td>-55.9920</td>\n",
       "      <td>-0.073957</td>\n",
       "      <td>-0.089951</td>\n",
       "      <td>0.12740</td>\n",
       "      <td>1.2754</td>\n",
       "      <td>0.11300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.796020</td>\n",
       "      <td>0.59074</td>\n",
       "      <td>2.878700</td>\n",
       "      <td>7.6524</td>\n",
       "      <td>3.3302</td>\n",
       "      <td>147.560</td>\n",
       "      <td>2.4735</td>\n",
       "      <td>5.9299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.781097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048179</td>\n",
       "      <td>0.55041</td>\n",
       "      <td>0.10765</td>\n",
       "      <td>1.2437</td>\n",
       "      <td>-22.9590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>0.81682</td>\n",
       "      <td>1.5150</td>\n",
       "      <td>0.44959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107160</td>\n",
       "      <td>0.77048</td>\n",
       "      <td>0.139380</td>\n",
       "      <td>10.1180</td>\n",
       "      <td>4.0950</td>\n",
       "      <td>106.430</td>\n",
       "      <td>3.4294</td>\n",
       "      <td>3.3622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.539786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1        2       3         4         5         6        7  \\\n",
       "0  0.088238  0.55472  0.01134  1.0205  -66.5200  0.342040  0.109490  0.57752   \n",
       "1 -0.006202  0.48465  0.23298  1.5998    6.1825  0.000000 -0.006202  1.06340   \n",
       "2  0.130240  0.22142  0.57751  3.6082  120.0400  0.187640  0.162120  3.05900   \n",
       "3 -0.089951  0.88700  0.26927  1.5222  -55.9920 -0.073957 -0.089951  0.12740   \n",
       "4  0.048179  0.55041  0.10765  1.2437  -22.9590  0.000000  0.059280  0.81682   \n",
       "\n",
       "        8        9  ...        56       57        58       59      60  \\\n",
       "0  1.0881  0.32036  ...  0.275430  0.91905  0.002024   7.2711  4.7343   \n",
       "1  1.2757  0.51535  ... -0.012035  1.00470  0.152220   6.0911  3.2749   \n",
       "2  1.1415  0.67731  ...  0.192290  0.87604  0.000000   8.7934  2.9870   \n",
       "3  1.2754  0.11300  ... -0.796020  0.59074  2.878700   7.6524  3.3302   \n",
       "4  1.5150  0.44959  ...  0.107160  0.77048  0.139380  10.1180  4.0950   \n",
       "\n",
       "        61      62      63   64  random_sample  \n",
       "0  142.760  2.5568  3.2597  0.0       0.427821  \n",
       "1  111.140  3.2841  3.3700  0.0       0.046901  \n",
       "2   71.531  5.1027  5.6188  0.0       0.730375  \n",
       "3  147.560  2.4735  5.9299  0.0       0.781097  \n",
       "4  106.430  3.4294  3.3622  0.0       0.539786  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column 64 is the classification column indicating whether firm went bunkrupt or not. If the random number is less\n",
    "#0.8 then its in the training set\n",
    "y_train = df[64][df['random_sample'] <=.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the random number is greater than 0.8, then it is in the test set\n",
    "y_test = df[64][df['random_sample'] >.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.iloc[:,0:64][df['random_sample'] <=.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df.iloc[:,0:64][df['random_sample'] >.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.078518</td>\n",
       "      <td>0.20546</td>\n",
       "      <td>0.103930</td>\n",
       "      <td>2.7939</td>\n",
       "      <td>77.7840</td>\n",
       "      <td>0.36515</td>\n",
       "      <td>0.093388</td>\n",
       "      <td>3.86720</td>\n",
       "      <td>1.23220</td>\n",
       "      <td>0.79454</td>\n",
       "      <td>...</td>\n",
       "      <td>12885.00</td>\n",
       "      <td>0.188420</td>\n",
       "      <td>0.098822</td>\n",
       "      <td>0.81158</td>\n",
       "      <td>0.185660</td>\n",
       "      <td>11.3790</td>\n",
       "      <td>3.1692</td>\n",
       "      <td>53.575</td>\n",
       "      <td>6.8129</td>\n",
       "      <td>0.47096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.011567</td>\n",
       "      <td>0.35237</td>\n",
       "      <td>0.073708</td>\n",
       "      <td>1.2583</td>\n",
       "      <td>-43.3650</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.017250</td>\n",
       "      <td>1.83790</td>\n",
       "      <td>0.96593</td>\n",
       "      <td>0.64763</td>\n",
       "      <td>...</td>\n",
       "      <td>446.76</td>\n",
       "      <td>0.039168</td>\n",
       "      <td>0.017860</td>\n",
       "      <td>0.98218</td>\n",
       "      <td>0.097927</td>\n",
       "      <td>5.4821</td>\n",
       "      <td>5.7226</td>\n",
       "      <td>107.840</td>\n",
       "      <td>3.3848</td>\n",
       "      <td>1.50710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.161690</td>\n",
       "      <td>0.59243</td>\n",
       "      <td>0.402650</td>\n",
       "      <td>1.6804</td>\n",
       "      <td>-39.4520</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.202520</td>\n",
       "      <td>0.68796</td>\n",
       "      <td>2.34010</td>\n",
       "      <td>0.40757</td>\n",
       "      <td>...</td>\n",
       "      <td>828.48</td>\n",
       "      <td>0.097682</td>\n",
       "      <td>0.396720</td>\n",
       "      <td>0.91425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>131.2200</td>\n",
       "      <td>6.4877</td>\n",
       "      <td>92.302</td>\n",
       "      <td>3.9544</td>\n",
       "      <td>420.19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.086244</td>\n",
       "      <td>0.53789</td>\n",
       "      <td>0.155710</td>\n",
       "      <td>1.2917</td>\n",
       "      <td>-5.6906</td>\n",
       "      <td>0.22244</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.83489</td>\n",
       "      <td>1.08490</td>\n",
       "      <td>0.44908</td>\n",
       "      <td>...</td>\n",
       "      <td>21772.00</td>\n",
       "      <td>0.078252</td>\n",
       "      <td>0.192050</td>\n",
       "      <td>0.92175</td>\n",
       "      <td>0.008899</td>\n",
       "      <td>23.3940</td>\n",
       "      <td>2.7398</td>\n",
       "      <td>140.370</td>\n",
       "      <td>2.6003</td>\n",
       "      <td>4.47270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.023928</td>\n",
       "      <td>0.79174</td>\n",
       "      <td>0.147050</td>\n",
       "      <td>1.1857</td>\n",
       "      <td>2.9638</td>\n",
       "      <td>0.11445</td>\n",
       "      <td>0.023928</td>\n",
       "      <td>0.25406</td>\n",
       "      <td>1.01500</td>\n",
       "      <td>0.20115</td>\n",
       "      <td>...</td>\n",
       "      <td>7120.70</td>\n",
       "      <td>0.014751</td>\n",
       "      <td>0.118960</td>\n",
       "      <td>0.98525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.6750</td>\n",
       "      <td>4.0245</td>\n",
       "      <td>99.028</td>\n",
       "      <td>3.6858</td>\n",
       "      <td>47.67600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1         2       3        4        5         6        7   \\\n",
       "7   0.078518  0.20546  0.103930  2.7939  77.7840  0.36515  0.093388  3.86720   \n",
       "13  0.011567  0.35237  0.073708  1.2583 -43.3650  0.00000  0.017250  1.83790   \n",
       "26  0.161690  0.59243  0.402650  1.6804 -39.4520  0.00000  0.202520  0.68796   \n",
       "31  0.086244  0.53789  0.155710  1.2917  -5.6906  0.22244  0.102800  0.83489   \n",
       "40  0.023928  0.79174  0.147050  1.1857   2.9638  0.11445  0.023928  0.25406   \n",
       "\n",
       "         8        9   ...        54        55        56       57        58  \\\n",
       "7   1.23220  0.79454  ...  12885.00  0.188420  0.098822  0.81158  0.185660   \n",
       "13  0.96593  0.64763  ...    446.76  0.039168  0.017860  0.98218  0.097927   \n",
       "26  2.34010  0.40757  ...    828.48  0.097682  0.396720  0.91425  0.000000   \n",
       "31  1.08490  0.44908  ...  21772.00  0.078252  0.192050  0.92175  0.008899   \n",
       "40  1.01500  0.20115  ...   7120.70  0.014751  0.118960  0.98525  0.000000   \n",
       "\n",
       "          59      60       61      62         63  \n",
       "7    11.3790  3.1692   53.575  6.8129    0.47096  \n",
       "13    5.4821  5.7226  107.840  3.3848    1.50710  \n",
       "26  131.2200  6.4877   92.302  3.9544  420.19000  \n",
       "31   23.3940  2.7398  140.370  2.6003    4.47270  \n",
       "40   23.6750  4.0245   99.028  3.6858   47.67600  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1.,random_state=1,max_iter = 200, tol=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brett/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='lbfgs', tol=0.1, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = lr.predict_proba(x_train).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.928\n"
     ]
    }
   ],
   "source": [
    "print (\"Train Accuracy: %.3f\" % accuracy_score(y_train,y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = lr.predict_proba(x_test).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.920\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: %.3f\" % accuracy_score(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With scaled variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = mms.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled = mms.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='lbfgs', tol=0.1, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = lr.predict_proba(x_train_scaled).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Train Accuracy: 0.933\n"
     ]
    }
   ],
   "source": [
    "print (\"Logistic Train Accuracy: %.3f\" % accuracy_score(y_train,y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = lr.predict_proba(x_test_scaled).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Test Accuracy: 0.926\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Test Accuracy: %.3f\" % accuracy_score(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero coefficients: 63\n"
     ]
    }
   ],
   "source": [
    "num_coeff = 0\n",
    "for i in range(len(lr.coef_[0])):\n",
    "    #print ('coefficient %i = %.2f ' % (i, lr.coef_[0][i]))\n",
    "    if abs(lr.coef_[0][i]) > .01:\n",
    "        num_coeff += 1\n",
    "        \n",
    "print ('Number of non-zero coefficients: %i' %num_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel = 'linear',C=1.0, random_state=1, probability = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=1, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = svm.predict_proba(x_train_scaled).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train Accuracy: 0.934\n"
     ]
    }
   ],
   "source": [
    "print (\"SVM Train Accuracy: %.3f\" % accuracy_score(y_train,y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = lr.predict_proba(x_test_scaled).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Accuracy: 0.926\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Test Accuracy: %.3f\" % accuracy_score(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtree = DecisionTreeClassifier(criterion='gini',max_depth=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = xtree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(153.45000000000002, 190.26, 'X[20] <= 0.001\\ngini = 0.127\\nsamples = 4753\\nvalue = [4429, 324]'),\n",
       " Text(83.7, 135.9, 'X[28] <= 4.85\\ngini = 0.091\\nsamples = 84\\nvalue = [4, 80]'),\n",
       " Text(55.800000000000004, 81.53999999999999, 'X[7] <= 16.712\\ngini = 0.048\\nsamples = 82\\nvalue = [2, 80]'),\n",
       " Text(27.900000000000002, 27.180000000000007, 'gini = 0.0\\nsamples = 79\\nvalue = [0, 79]'),\n",
       " Text(83.7, 27.180000000000007, 'gini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(111.60000000000001, 81.53999999999999, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(223.20000000000002, 135.9, 'X[38] <= -0.037\\ngini = 0.099\\nsamples = 4669\\nvalue = [4425, 244]'),\n",
       " Text(167.4, 81.53999999999999, 'X[55] <= 0.026\\ngini = 0.396\\nsamples = 489\\nvalue = [356, 133]'),\n",
       " Text(139.5, 27.180000000000007, 'gini = 0.357\\nsamples = 456\\nvalue = [350, 106]'),\n",
       " Text(195.3, 27.180000000000007, 'gini = 0.298\\nsamples = 33\\nvalue = [6, 27]'),\n",
       " Text(279.0, 81.53999999999999, 'X[20] <= 0.756\\ngini = 0.052\\nsamples = 4180\\nvalue = [4069, 111]'),\n",
       " Text(251.10000000000002, 27.180000000000007, 'gini = 0.216\\nsamples = 187\\nvalue = [164, 23]'),\n",
       " Text(306.90000000000003, 27.180000000000007, 'gini = 0.043\\nsamples = 3993\\nvalue = [3905, 88]')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.plot_tree(results.fit(x_train, y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = xtree.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Accuracy: 0.953\n"
     ]
    }
   ],
   "source": [
    "print (\"Decision Tree Train Accuracy: %.3f\" % accuracy_score(y_train,y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = xtree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Test Accuracy: 0.944\n"
     ]
    }
   ],
   "source": [
    "print (\"Decision Tree Test Accuracy: %.3f\" % accuracy_score(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(criterion='gini', n_estimators = 25, random_state =1, n_jobs =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=2,\n",
       "                       oob_score=False, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = forest.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Accuracy: 0.999\n"
     ]
    }
   ],
   "source": [
    "print (\"Random Forest Train Accuracy: %.3f\" % accuracy_score(y_train,y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy: 0.944\n"
     ]
    }
   ],
   "source": [
    "print (\"Random Forest Test Accuracy: %.3f\" % accuracy_score(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
