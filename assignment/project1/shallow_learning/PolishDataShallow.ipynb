{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load your own path here where the datasets reside\n",
    "# path = '/home/brett/Documents/Datasets/ten-datasets/'\n",
    "path = '../ten-datasets/'\n",
    "\n",
    "#load the dataset into a dataframe\n",
    "polishdata = loadmat(path + 'Polish.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only looking at a single year at this stage. Not sure whether they is need to join up multiple years or not.\n",
    "df = pd.DataFrame(polishdata['year5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088238</td>\n",
       "      <td>0.55472</td>\n",
       "      <td>0.01134</td>\n",
       "      <td>1.0205</td>\n",
       "      <td>-66.5200</td>\n",
       "      <td>0.342040</td>\n",
       "      <td>0.109490</td>\n",
       "      <td>0.57752</td>\n",
       "      <td>1.0881</td>\n",
       "      <td>0.32036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080955</td>\n",
       "      <td>0.275430</td>\n",
       "      <td>0.91905</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>7.2711</td>\n",
       "      <td>4.7343</td>\n",
       "      <td>142.760</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>3.2597</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006202</td>\n",
       "      <td>0.48465</td>\n",
       "      <td>0.23298</td>\n",
       "      <td>1.5998</td>\n",
       "      <td>6.1825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>1.06340</td>\n",
       "      <td>1.2757</td>\n",
       "      <td>0.51535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028591</td>\n",
       "      <td>-0.012035</td>\n",
       "      <td>1.00470</td>\n",
       "      <td>0.152220</td>\n",
       "      <td>6.0911</td>\n",
       "      <td>3.2749</td>\n",
       "      <td>111.140</td>\n",
       "      <td>3.2841</td>\n",
       "      <td>3.3700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130240</td>\n",
       "      <td>0.22142</td>\n",
       "      <td>0.57751</td>\n",
       "      <td>3.6082</td>\n",
       "      <td>120.0400</td>\n",
       "      <td>0.187640</td>\n",
       "      <td>0.162120</td>\n",
       "      <td>3.05900</td>\n",
       "      <td>1.1415</td>\n",
       "      <td>0.67731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123960</td>\n",
       "      <td>0.192290</td>\n",
       "      <td>0.87604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.7934</td>\n",
       "      <td>2.9870</td>\n",
       "      <td>71.531</td>\n",
       "      <td>5.1027</td>\n",
       "      <td>5.6188</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089951</td>\n",
       "      <td>0.88700</td>\n",
       "      <td>0.26927</td>\n",
       "      <td>1.5222</td>\n",
       "      <td>-55.9920</td>\n",
       "      <td>-0.073957</td>\n",
       "      <td>-0.089951</td>\n",
       "      <td>0.12740</td>\n",
       "      <td>1.2754</td>\n",
       "      <td>0.11300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418840</td>\n",
       "      <td>-0.796020</td>\n",
       "      <td>0.59074</td>\n",
       "      <td>2.878700</td>\n",
       "      <td>7.6524</td>\n",
       "      <td>3.3302</td>\n",
       "      <td>147.560</td>\n",
       "      <td>2.4735</td>\n",
       "      <td>5.9299</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048179</td>\n",
       "      <td>0.55041</td>\n",
       "      <td>0.10765</td>\n",
       "      <td>1.2437</td>\n",
       "      <td>-22.9590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>0.81682</td>\n",
       "      <td>1.5150</td>\n",
       "      <td>0.44959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.107160</td>\n",
       "      <td>0.77048</td>\n",
       "      <td>0.139380</td>\n",
       "      <td>10.1180</td>\n",
       "      <td>4.0950</td>\n",
       "      <td>106.430</td>\n",
       "      <td>3.4294</td>\n",
       "      <td>3.3622</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2       3         4         5         6        7   \\\n",
       "0  0.088238  0.55472  0.01134  1.0205  -66.5200  0.342040  0.109490  0.57752   \n",
       "1 -0.006202  0.48465  0.23298  1.5998    6.1825  0.000000 -0.006202  1.06340   \n",
       "2  0.130240  0.22142  0.57751  3.6082  120.0400  0.187640  0.162120  3.05900   \n",
       "3 -0.089951  0.88700  0.26927  1.5222  -55.9920 -0.073957 -0.089951  0.12740   \n",
       "4  0.048179  0.55041  0.10765  1.2437  -22.9590  0.000000  0.059280  0.81682   \n",
       "\n",
       "       8        9   ...        55        56       57        58       59  \\\n",
       "0  1.0881  0.32036  ...  0.080955  0.275430  0.91905  0.002024   7.2711   \n",
       "1  1.2757  0.51535  ... -0.028591 -0.012035  1.00470  0.152220   6.0911   \n",
       "2  1.1415  0.67731  ...  0.123960  0.192290  0.87604  0.000000   8.7934   \n",
       "3  1.2754  0.11300  ...  0.418840 -0.796020  0.59074  2.878700   7.6524   \n",
       "4  1.5150  0.44959  ...  0.240400  0.107160  0.77048  0.139380  10.1180   \n",
       "\n",
       "       60       61      62      63   64  \n",
       "0  4.7343  142.760  2.5568  3.2597  0.0  \n",
       "1  3.2749  111.140  3.2841  3.3700  0.0  \n",
       "2  2.9870   71.531  5.1027  5.6188  0.0  \n",
       "3  3.3302  147.560  2.4735  5.9299  0.0  \n",
       "4  4.0950  106.430  3.4294  3.3622  0.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the following creates an 80/20 train/test split but this could be done more easily using sklearn functions which I'll look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a random number column so that we can split the data\n",
    "df['random_sample'] = np.random.rand(1,len(df)).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5910, 66)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>random_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088238</td>\n",
       "      <td>0.55472</td>\n",
       "      <td>0.01134</td>\n",
       "      <td>1.0205</td>\n",
       "      <td>-66.5200</td>\n",
       "      <td>0.342040</td>\n",
       "      <td>0.109490</td>\n",
       "      <td>0.57752</td>\n",
       "      <td>1.0881</td>\n",
       "      <td>0.32036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275430</td>\n",
       "      <td>0.91905</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>7.2711</td>\n",
       "      <td>4.7343</td>\n",
       "      <td>142.760</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>3.2597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006202</td>\n",
       "      <td>0.48465</td>\n",
       "      <td>0.23298</td>\n",
       "      <td>1.5998</td>\n",
       "      <td>6.1825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>1.06340</td>\n",
       "      <td>1.2757</td>\n",
       "      <td>0.51535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012035</td>\n",
       "      <td>1.00470</td>\n",
       "      <td>0.152220</td>\n",
       "      <td>6.0911</td>\n",
       "      <td>3.2749</td>\n",
       "      <td>111.140</td>\n",
       "      <td>3.2841</td>\n",
       "      <td>3.3700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.792667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130240</td>\n",
       "      <td>0.22142</td>\n",
       "      <td>0.57751</td>\n",
       "      <td>3.6082</td>\n",
       "      <td>120.0400</td>\n",
       "      <td>0.187640</td>\n",
       "      <td>0.162120</td>\n",
       "      <td>3.05900</td>\n",
       "      <td>1.1415</td>\n",
       "      <td>0.67731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192290</td>\n",
       "      <td>0.87604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.7934</td>\n",
       "      <td>2.9870</td>\n",
       "      <td>71.531</td>\n",
       "      <td>5.1027</td>\n",
       "      <td>5.6188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089951</td>\n",
       "      <td>0.88700</td>\n",
       "      <td>0.26927</td>\n",
       "      <td>1.5222</td>\n",
       "      <td>-55.9920</td>\n",
       "      <td>-0.073957</td>\n",
       "      <td>-0.089951</td>\n",
       "      <td>0.12740</td>\n",
       "      <td>1.2754</td>\n",
       "      <td>0.11300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.796020</td>\n",
       "      <td>0.59074</td>\n",
       "      <td>2.878700</td>\n",
       "      <td>7.6524</td>\n",
       "      <td>3.3302</td>\n",
       "      <td>147.560</td>\n",
       "      <td>2.4735</td>\n",
       "      <td>5.9299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.337065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048179</td>\n",
       "      <td>0.55041</td>\n",
       "      <td>0.10765</td>\n",
       "      <td>1.2437</td>\n",
       "      <td>-22.9590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>0.81682</td>\n",
       "      <td>1.5150</td>\n",
       "      <td>0.44959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107160</td>\n",
       "      <td>0.77048</td>\n",
       "      <td>0.139380</td>\n",
       "      <td>10.1180</td>\n",
       "      <td>4.0950</td>\n",
       "      <td>106.430</td>\n",
       "      <td>3.4294</td>\n",
       "      <td>3.3622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1        2       3         4         5         6        7  \\\n",
       "0  0.088238  0.55472  0.01134  1.0205  -66.5200  0.342040  0.109490  0.57752   \n",
       "1 -0.006202  0.48465  0.23298  1.5998    6.1825  0.000000 -0.006202  1.06340   \n",
       "2  0.130240  0.22142  0.57751  3.6082  120.0400  0.187640  0.162120  3.05900   \n",
       "3 -0.089951  0.88700  0.26927  1.5222  -55.9920 -0.073957 -0.089951  0.12740   \n",
       "4  0.048179  0.55041  0.10765  1.2437  -22.9590  0.000000  0.059280  0.81682   \n",
       "\n",
       "        8        9  ...        56       57        58       59      60  \\\n",
       "0  1.0881  0.32036  ...  0.275430  0.91905  0.002024   7.2711  4.7343   \n",
       "1  1.2757  0.51535  ... -0.012035  1.00470  0.152220   6.0911  3.2749   \n",
       "2  1.1415  0.67731  ...  0.192290  0.87604  0.000000   8.7934  2.9870   \n",
       "3  1.2754  0.11300  ... -0.796020  0.59074  2.878700   7.6524  3.3302   \n",
       "4  1.5150  0.44959  ...  0.107160  0.77048  0.139380  10.1180  4.0950   \n",
       "\n",
       "        61      62      63   64  random_sample  \n",
       "0  142.760  2.5568  3.2597  0.0       0.214712  \n",
       "1  111.140  3.2841  3.3700  0.0       0.792667  \n",
       "2   71.531  5.1027  5.6188  0.0       0.313965  \n",
       "3  147.560  2.4735  5.9299  0.0       0.337065  \n",
       "4  106.430  3.4294  3.3622  0.0       0.405731  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column 64 is the classification column indicating whether firm went bunkrupt or not. If the random number is less\n",
    "#0.8 then its in the training set\n",
    "y_train = df[64][df['random_sample'] <=.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the random number is greater than 0.8, then it is in the test set\n",
    "y_test = df[64][df['random_sample'] >.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.iloc[:,0:64][df['random_sample'] <=.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df.iloc[:,0:64][df['random_sample'] >.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.231560</td>\n",
       "      <td>0.51047</td>\n",
       "      <td>0.47291</td>\n",
       "      <td>1.9393</td>\n",
       "      <td>15.1020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.287690</td>\n",
       "      <td>0.95899</td>\n",
       "      <td>1.7915</td>\n",
       "      <td>0.48953</td>\n",
       "      <td>...</td>\n",
       "      <td>7008.80</td>\n",
       "      <td>0.184030</td>\n",
       "      <td>0.47303</td>\n",
       "      <td>0.83996</td>\n",
       "      <td>0.014242</td>\n",
       "      <td>4.6071</td>\n",
       "      <td>4.9220</td>\n",
       "      <td>102.580</td>\n",
       "      <td>3.5581</td>\n",
       "      <td>75.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.099486</td>\n",
       "      <td>0.59991</td>\n",
       "      <td>0.37489</td>\n",
       "      <td>1.6529</td>\n",
       "      <td>19.0360</td>\n",
       "      <td>0.21084</td>\n",
       "      <td>0.123950</td>\n",
       "      <td>0.66690</td>\n",
       "      <td>1.0972</td>\n",
       "      <td>0.40009</td>\n",
       "      <td>...</td>\n",
       "      <td>6131.00</td>\n",
       "      <td>0.088581</td>\n",
       "      <td>0.24866</td>\n",
       "      <td>0.91142</td>\n",
       "      <td>0.064344</td>\n",
       "      <td>5.4655</td>\n",
       "      <td>2.4784</td>\n",
       "      <td>130.020</td>\n",
       "      <td>2.8072</td>\n",
       "      <td>31.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.130330</td>\n",
       "      <td>0.77424</td>\n",
       "      <td>0.21070</td>\n",
       "      <td>1.2721</td>\n",
       "      <td>7.3584</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.164870</td>\n",
       "      <td>0.29159</td>\n",
       "      <td>2.7657</td>\n",
       "      <td>0.22576</td>\n",
       "      <td>...</td>\n",
       "      <td>575.75</td>\n",
       "      <td>0.079606</td>\n",
       "      <td>0.57728</td>\n",
       "      <td>0.94055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.6060</td>\n",
       "      <td>3.5932</td>\n",
       "      <td>102.180</td>\n",
       "      <td>3.5721</td>\n",
       "      <td>183.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.072197</td>\n",
       "      <td>0.79244</td>\n",
       "      <td>0.28691</td>\n",
       "      <td>1.4024</td>\n",
       "      <td>35.0650</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.093762</td>\n",
       "      <td>0.26193</td>\n",
       "      <td>2.2096</td>\n",
       "      <td>0.20756</td>\n",
       "      <td>...</td>\n",
       "      <td>126.34</td>\n",
       "      <td>0.072076</td>\n",
       "      <td>0.34783</td>\n",
       "      <td>0.95757</td>\n",
       "      <td>0.121840</td>\n",
       "      <td>26.7060</td>\n",
       "      <td>2.6399</td>\n",
       "      <td>117.790</td>\n",
       "      <td>3.0986</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.161690</td>\n",
       "      <td>0.59243</td>\n",
       "      <td>0.40265</td>\n",
       "      <td>1.6804</td>\n",
       "      <td>-39.4520</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.202520</td>\n",
       "      <td>0.68796</td>\n",
       "      <td>2.3401</td>\n",
       "      <td>0.40757</td>\n",
       "      <td>...</td>\n",
       "      <td>828.48</td>\n",
       "      <td>0.097682</td>\n",
       "      <td>0.39672</td>\n",
       "      <td>0.91425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>131.2200</td>\n",
       "      <td>6.4877</td>\n",
       "      <td>92.302</td>\n",
       "      <td>3.9544</td>\n",
       "      <td>420.190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1        2       3        4        5         6        7   \\\n",
       "5   0.231560  0.51047  0.47291  1.9393  15.1020  0.00000  0.287690  0.95899   \n",
       "6   0.099486  0.59991  0.37489  1.6529  19.0360  0.21084  0.123950  0.66690   \n",
       "17  0.130330  0.77424  0.21070  1.2721   7.3584  0.00000  0.164870  0.29159   \n",
       "22  0.072197  0.79244  0.28691  1.4024  35.0650  0.00000  0.093762  0.26193   \n",
       "26  0.161690  0.59243  0.40265  1.6804 -39.4520  0.00000  0.202520  0.68796   \n",
       "\n",
       "        8        9   ...       54        55       56       57        58  \\\n",
       "5   1.7915  0.48953  ...  7008.80  0.184030  0.47303  0.83996  0.014242   \n",
       "6   1.0972  0.40009  ...  6131.00  0.088581  0.24866  0.91142  0.064344   \n",
       "17  2.7657  0.22576  ...   575.75  0.079606  0.57728  0.94055  0.000000   \n",
       "22  2.2096  0.20756  ...   126.34  0.072076  0.34783  0.95757  0.121840   \n",
       "26  2.3401  0.40757  ...   828.48  0.097682  0.39672  0.91425  0.000000   \n",
       "\n",
       "          59      60       61      62       63  \n",
       "5     4.6071  4.9220  102.580  3.5581   75.941  \n",
       "6     5.4655  2.4784  130.020  2.8072   31.645  \n",
       "17   17.6060  3.5932  102.180  3.5721  183.640  \n",
       "22   26.7060  2.6399  117.790  3.0986    0.000  \n",
       "26  131.2200  6.4877   92.302  3.9544  420.190  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1.,random_state=1,max_iter = 100, tol=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tommy/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='lbfgs', tol=0.1, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = lr.predict_proba(x_train).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.924\n"
     ]
    }
   ],
   "source": [
    "print (\"Train Accuracy: %.3f\" % accuracy_score(y_train,y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = lr.predict_proba(x_test).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.931\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: %.3f\" % accuracy_score(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With scaled variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = mms.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled = mms.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='lbfgs', tol=0.1, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = lr.predict_proba(x_train_scaled).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Train Accuracy: 0.929\n"
     ]
    }
   ],
   "source": [
    "print (\"Logistic Train Accuracy: %.3f\" % accuracy_score(y_train,y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = lr.predict_proba(x_test_scaled).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Test Accuracy: 0.939\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Test Accuracy: %.3f\" % accuracy_score(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero coefficients: 61\n"
     ]
    }
   ],
   "source": [
    "num_coeff = 0\n",
    "for i in range(len(lr.coef_[0])):\n",
    "    #print ('coefficient %i = %.2f ' % (i, lr.coef_[0][i]))\n",
    "    if abs(lr.coef_[0][i]) > .01:\n",
    "        num_coeff += 1\n",
    "        \n",
    "print ('Number of non-zero coefficients: %i' %num_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel = 'linear',C=1.0, random_state=1, probability = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=1, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = svm.predict_proba(x_train_scaled).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train Accuracy: 0.930\n"
     ]
    }
   ],
   "source": [
    "print (\"SVM Train Accuracy: %.3f\" % accuracy_score(y_train,y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = lr.predict_proba(x_test_scaled).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Accuracy: 0.939\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Test Accuracy: %.3f\" % accuracy_score(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtree = DecisionTreeClassifier(criterion='gini',max_depth=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = xtree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(167.4, 190.26, 'X[20] <= 0.001\\ngini = 0.133\\nsamples = 4741\\nvalue = [4401, 340]'),\n",
       " Text(83.7, 135.9, 'X[28] <= 4.52\\ngini = 0.124\\nsamples = 90\\nvalue = [6, 84]'),\n",
       " Text(41.85, 81.53999999999999, 'X[7] <= 382.595\\ngini = 0.046\\nsamples = 85\\nvalue = [2, 83]'),\n",
       " Text(20.925, 27.180000000000007, 'gini = 0.024\\nsamples = 84\\nvalue = [1, 83]'),\n",
       " Text(62.775000000000006, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(125.55000000000001, 81.53999999999999, 'X[50] <= 0.415\\ngini = 0.32\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(104.625, 27.180000000000007, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(146.475, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(251.10000000000002, 135.9, 'X[38] <= -0.037\\ngini = 0.104\\nsamples = 4651\\nvalue = [4395, 256]'),\n",
       " Text(209.25, 81.53999999999999, 'X[55] <= 0.023\\ngini = 0.417\\nsamples = 476\\nvalue = [335, 141]'),\n",
       " Text(188.32500000000002, 27.180000000000007, 'gini = 0.378\\nsamples = 442\\nvalue = [330, 112]'),\n",
       " Text(230.175, 27.180000000000007, 'gini = 0.251\\nsamples = 34\\nvalue = [5, 29]'),\n",
       " Text(292.95, 81.53999999999999, 'X[45] <= 0.35\\ngini = 0.054\\nsamples = 4175\\nvalue = [4060, 115]'),\n",
       " Text(272.02500000000003, 27.180000000000007, 'gini = 0.21\\nsamples = 293\\nvalue = [258, 35]'),\n",
       " Text(313.875, 27.180000000000007, 'gini = 0.04\\nsamples = 3882\\nvalue = [3802, 80]')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.plot_tree(results.fit(x_train, y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = xtree.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Accuracy: 0.951\n"
     ]
    }
   ],
   "source": [
    "print (\"Decision Tree Train Accuracy: %.3f\" % accuracy_score(y_train,y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = xtree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Test Accuracy: 0.953\n"
     ]
    }
   ],
   "source": [
    "print (\"Decision Tree Test Accuracy: %.3f\" % accuracy_score(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(criterion='gini', n_estimators = 25, random_state =1, n_jobs =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=2,\n",
       "                       oob_score=False, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = forest.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Accuracy: 0.999\n"
     ]
    }
   ],
   "source": [
    "print (\"Random Forest Train Accuracy: %.3f\" % accuracy_score(y_train,y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy: 0.951\n"
     ]
    }
   ],
   "source": [
    "print (\"Random Forest Test Accuracy: %.3f\" % accuracy_score(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
