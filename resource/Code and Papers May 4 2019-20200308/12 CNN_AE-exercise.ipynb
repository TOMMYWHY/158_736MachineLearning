{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preprocessing for Fashion MNIST\n",
    "-  Fashion MNIST contains 70,000 grayscale images in 10 categories. \n",
    "-  The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
    "-  It's a slightly more challenging problem than regular MNIST\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0-rc1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Download dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Scale value to range 0 to 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN  + Auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Add layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 1TensorFlow and tf.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Flatten, Dense,UpSampling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_x = np.expand_dims(train_images,-1)\n",
    "test_x = np.expand_dims(test_images,-1)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 CNN_AE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dp1/.conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 2)         290       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 2)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 2)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 2)           38        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 2)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 16)        304       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 1)         145       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 937\n",
      "Trainable params: 937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#1st convolution layer\n",
    "model.add(Conv2D(16, (3, 3) #16 is number of filters and (3, 3) is the size of the filter.\n",
    ", padding='same', input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    " \n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(2,(3, 3), padding='same')) # apply 2 filters sized of (3x3)\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    " \n",
    "#here compressed version\n",
    " \n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(2,(3, 3), padding='same')) # apply 2 filters sized of (3x3)\n",
    "model.add(Activation('relu'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    " \n",
    "#4rd convolution layer\n",
    "model.add(Conv2D(16,(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    " \n",
    "model.add(Conv2D(1,(3, 3), padding='same'))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dp1/.conda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 22s 367us/step - loss: 0.3283 - val_loss: 0.3031\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 22s 361us/step - loss: 0.2968 - val_loss: 0.2953\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 22s 364us/step - loss: 0.2911 - val_loss: 0.2887\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.2888 - val_loss: 0.2921\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 22s 365us/step - loss: 0.2871 - val_loss: 0.2903\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 22s 359us/step - loss: 0.2863 - val_loss: 0.2873\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 21s 357us/step - loss: 0.2853 - val_loss: 0.2861\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 22s 363us/step - loss: 0.2850 - val_loss: 0.2858\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 22s 365us/step - loss: 0.2842 - val_loss: 0.2846\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 22s 360us/step - loss: 0.2836 - val_loss: 0.2898\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "## Compile and fit\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "model.fit(train_x, train_x, epochs=10, validation_data=(test_x, test_x))\n",
    "\n",
    "## test or prediction\n",
    "restored_imgs = model.predict(test_x)\n",
    "\n",
    "\n",
    "print(test_x.shape)\n",
    "print(restored_imgs.shape)\n",
    "\n",
    "test_x_r = test_x.reshape((len(test_x), np.prod(test_x.shape[1:])))\n",
    "restored_imgs_r = restored_imgs.reshape((len(restored_imgs), np.prod(restored_imgs.shape[1:])))\n",
    "\n",
    "print(test_x_r.shape)\n",
    "print(restored_imgs_r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise on Cifar-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different from former example, this exmaple has two difference.\n",
    "\n",
    "(1) The data set is different;\n",
    "\n",
    "(2) Build a different CNN-AE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 add layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1TensorFlow and tf.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Flatten, Dense,UpSampling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#####  Input your codes  #####\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 build  CNN_AE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#####  Input your codes  #####\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 323s 6ms/step - loss: -1908.4240 - val_loss: -1921.5222\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 326s 7ms/step - loss: -1908.4241 - val_loss: -1921.5222\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "## Compile and fit\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "model.fit(train_images, train_images, epochs=2, validation_data=(test_images, test_images))\n",
    "\n",
    "## test or prediction\n",
    "restored_imgs = model.predict(test_images)\n",
    "\n",
    "\n",
    "print(test_images.shape)\n",
    "print(restored_imgs.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
